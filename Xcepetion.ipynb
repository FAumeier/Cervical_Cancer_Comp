{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create references to important directories we will use over and over\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = LESSON_HOME_DIR+'/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-11efcfff5b64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Instantiate plotting tool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#In Jupyter notebooks, you will need to run this command before doing any plotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Flo\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2128\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2129\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2130\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2132\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Flo\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2049\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2050\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2051\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2052\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-106>\u001b[0m in \u001b[0;36mmatplotlib\u001b[1;34m(self, line)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Flo\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Flo\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\magics\\pylab.py\u001b[0m in \u001b[0;36mmatplotlib\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Flo\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \"\"\"\n\u001b[0;32m   2902\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2903\u001b[1;33m         \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2904\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Flo\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[1;34m(gui, gui_select)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \"\"\"\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "#Instantiate plotting tool\n",
    "#In Jupyter notebooks, you will need to run this command before doing any plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Plan\n",
    "1. Create Validation and Sample sets\n",
    "2. Rearrange image files into their respective directories \n",
    "3. Finetune and Train model\n",
    "4. Generate predictions\n",
    "5. Validate predictions\n",
    "6. Submit predictions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Flo\\Source\\Repos\\Cervical_Cancer_Comp\\data\n"
     ]
    }
   ],
   "source": [
    "#Create directories\n",
    "%mkdir results\n",
    "%cd $DATA_HOME_DIR\n",
    "%mkdir valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Flo\\Source\\Repos\\Cervical_Cancer_Comp\\data\\valid\n",
      " Volume in Laufwerk C: hat keine Bezeichnung.\n",
      " Volumeseriennummer: 661E-8808\n",
      "\n",
      " Verzeichnis von C:\\Users\\Flo\\Source\\Repos\\Cervical_Cancer_Comp\\data\\valid\n",
      "\n",
      "17.05.2017  11:07    <DIR>          .\n",
      "17.05.2017  11:07    <DIR>          ..\n",
      "               0 Datei(en),              0 Bytes\n",
      "               2 Verzeichnis(se), 67.787.304.960 Bytes frei\n"
     ]
    }
   ],
   "source": [
    "#creating respecting class dirs in valid\n",
    "%cd valid/\n",
    "%ls\n",
    "%mkdir Type_1\n",
    "%mkdir Type_2\n",
    "%mkdir Type_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'C:\\\\Users\\\\Flo\\\\Source\\\\Repos\\\\Cervical_Cancer_Comp\\\\data\\\\valid'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current dir\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Flo\\Source\\Repos\\Cervical_Cancer_Comp\\data\\train\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in Laufwerk C: hat keine Bezeichnung.\n",
      " Volumeseriennummer: 661E-8808\n",
      "\n",
      " Verzeichnis von C:\\Users\\Flo\\Source\\Repos\\Cervical_Cancer_Comp\\data\\train\n",
      "\n",
      "17.05.2017  11:07    <DIR>          .\n",
      "17.05.2017  11:07    <DIR>          ..\n",
      "09.03.2017  00:06             6.148 .DS_Store\n",
      "17.05.2017  11:07    <DIR>          results\n",
      "09.03.2017  00:37    <DIR>          Type_1\n",
      "09.03.2017  00:37    <DIR>          Type_2\n",
      "09.03.2017  00:37    <DIR>          Type_3\n",
      "               1 Datei(en),          6.148 Bytes\n",
      "               6 Verzeichnis(se), 67.787.300.864 Bytes frei\n"
     ]
    }
   ],
   "source": [
    "%ls\n",
    "g = glob('**/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "validation_dir = DATA_HOME_DIR+'valid/' \n",
    "\n",
    "for i in range(444): os.rename(shuf[i], validation_dir + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Flo\\Source\\Repos\\Cervical_Cancer_Comp\\data\n",
      " Volume in Laufwerk C: hat keine Bezeichnung.\n",
      " Volumeseriennummer: 661E-8808\n",
      "\n",
      " Verzeichnis von C:\\Users\\Flo\\Source\\Repos\\Cervical_Cancer_Comp\\data\n",
      "\n",
      "17.05.2017  11:07    <DIR>          .\n",
      "17.05.2017  11:07    <DIR>          ..\n",
      "09.03.2017  00:37    <DIR>          test\n",
      "16.05.2017  20:14     2.071.977.419 test.7z\n",
      "17.05.2017  11:07    <DIR>          train\n",
      "16.05.2017  21:37     5.944.334.666 train.7z\n",
      "17.05.2017  11:07    <DIR>          valid\n",
      "               2 Datei(en),  8.016.312.085 Bytes\n",
      "               5 Verzeichnis(se), 67.785.396.224 Bytes frei\n",
      "C:\\Users\\Flo\\Source\\Repos\\Cervical_Cancer_Comp\\data\\valid\\Type_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Der Befehl \"wc\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "# check valid dir for type 1\n",
    "%cd $DATA_HOME_DIR\n",
    "%ls\n",
    "%cd valid/Type_1\n",
    "%ls -1 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/NBs/Cervical_Cancer_Comp/data/valid\n",
      "/home/paperspace/NBs/Cervical_Cancer_Comp/data/valid/Type_2\n",
      "229\r\n"
     ]
    }
   ],
   "source": [
    "# check valid dir for type 2\n",
    "%cd ..\n",
    "%cd Type_2\n",
    "% ls -1 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/NBs/Cervical_Cancer_Comp/data/valid\n",
      "/home/paperspace/NBs/Cervical_Cancer_Comp/data/valid/Type_3\n",
      "139\r\n"
     ]
    }
   ],
   "source": [
    "# check valid dir for type 2\n",
    "%cd ..\n",
    "%cd Type_3\n",
    "% ls -1 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Flo\\Source\\Repos\\Cervical_Cancer_Comp\\data\n",
      "C:\\Users\\Flo\\Source\\Repos\\Cervical_Cancer_Comp\\data\\test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Line magic function `%mv` not found.\n"
     ]
    }
   ],
   "source": [
    "# Create single 'unknown' class for test set\n",
    "%cd $DATA_HOME_DIR\n",
    "%cd test\n",
    "%mkdir unknown\n",
    "%mv *.jpg unknown/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as k\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = DATA_HOME_DIR+'/train'\n",
    "test_data_dir = DATA_HOME_DIR+'/test'\n",
    "validation_data_dir = DATA_HOME_DIR+'/valid'\n",
    "\n",
    "\n",
    "nb_train_samples = 1037\n",
    "nb_validation_samples = 444"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we are using Inception or Xception, we need to set the inputShape  to 299×299 pixels, followed by updating preprocess  to use a separate pre-processing function that performs a different type of scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters for model\n",
    "nb_classes = 3  # number of classes\n",
    "img_width, img_height = 299, 299  # change based on the shape/structure of your images\n",
    "batch_size = 16  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU/GPU memory capacity (powers of 2 values).\n",
    "nb_epoch = 50  # number of iteration the algorithm gets trained. 1 As test run\n",
    "\n",
    "momentum = 0.9  # sgd momentum to avoid local minimum\n",
    "transformation_ratio = .05  # how aggressive will be the data augmentation/transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Pre-trained InceptionV3 Model using imagenet dataset weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded!\n"
     ]
    }
   ],
   "source": [
    "# Pre-Trained CNN Model using imagenet dataset for pre-trained weights\n",
    "base_model = Xception(input_shape=(img_width, img_height, 3), weights='imagenet', include_top=False)\n",
    "print('Model Loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Defining own top model block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Top Model Block\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(nb_classes, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add your top layer block to your base model\n",
    "model = Model(base_model.input, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all layers of the based model that is already pre-trained.\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read Data and Augment it: Make sure to select augmentations that are appropriate to your images.\n",
    "# To save augmentations un-comment save lines and add to your flow parameters.\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1037 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                        target_size=(img_width, img_height),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 444 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                                  target_size=(img_width, img_height),\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='nadam',\n",
    "                  loss='categorical_crossentropy',  # categorical_crossentropy if multi-class classifier\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See: https://github.com/fchollet/keras/issues/5475\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting to Tune Model\n",
      "\n",
      "Epoch 1/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9920 - acc: 0.5258Epoch 00000: val_acc improved from -inf to 0.54630, saving model to weights-improvement-00-0.55.hdf5\n",
      "64/64 [==============================] - 224s - loss: 0.9922 - acc: 0.5244 - val_loss: 0.9694 - val_acc: 0.5463\n",
      "Epoch 2/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9468 - acc: 0.5743Epoch 00001: val_acc improved from 0.54630 to 0.54861, saving model to weights-improvement-01-0.55.hdf5\n",
      "64/64 [==============================] - 197s - loss: 0.9492 - acc: 0.5742 - val_loss: 0.9654 - val_acc: 0.5486\n",
      "Epoch 3/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9071 - acc: 0.5802Epoch 00002: val_acc did not improve\n",
      "64/64 [==============================] - 197s - loss: 0.9034 - acc: 0.5829 - val_loss: 0.9558 - val_acc: 0.5463\n",
      "Epoch 4/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8749 - acc: 0.6038Epoch 00003: val_acc improved from 0.54861 to 0.56944, saving model to weights-improvement-03-0.57.hdf5\n",
      "64/64 [==============================] - 197s - loss: 0.8743 - acc: 0.6051 - val_loss: 0.9229 - val_acc: 0.5694\n",
      "Epoch 5/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8555 - acc: 0.6157Epoch 00004: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.8534 - acc: 0.6168 - val_loss: 0.9575 - val_acc: 0.5278\n",
      "Epoch 6/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8512 - acc: 0.6050Epoch 00005: val_acc improved from 0.56944 to 0.58796, saving model to weights-improvement-05-0.59.hdf5\n",
      "64/64 [==============================] - 196s - loss: 0.8519 - acc: 0.6024 - val_loss: 0.9095 - val_acc: 0.5880\n",
      "Epoch 7/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8511 - acc: 0.5976Epoch 00006: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.8494 - acc: 0.5990 - val_loss: 0.9259 - val_acc: 0.5764\n",
      "Epoch 8/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8185 - acc: 0.6266Epoch 00007: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.8195 - acc: 0.6266 - val_loss: 0.9108 - val_acc: 0.5764\n",
      "Epoch 9/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8339 - acc: 0.6137Epoch 00008: val_acc did not improve\n",
      "64/64 [==============================] - 197s - loss: 0.8338 - acc: 0.6139 - val_loss: 0.9081 - val_acc: 0.5856\n",
      "Epoch 10/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8199 - acc: 0.6248Epoch 00009: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.8185 - acc: 0.6258 - val_loss: 0.9125 - val_acc: 0.5671\n",
      "Epoch 11/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7945 - acc: 0.6320Epoch 00010: val_acc did not improve\n",
      "64/64 [==============================] - 197s - loss: 0.7954 - acc: 0.6319 - val_loss: 0.9356 - val_acc: 0.5810\n",
      "Epoch 12/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8215 - acc: 0.6156Epoch 00011: val_acc improved from 0.58796 to 0.60185, saving model to weights-improvement-11-0.60.hdf5\n",
      "64/64 [==============================] - 196s - loss: 0.8220 - acc: 0.6167 - val_loss: 0.9225 - val_acc: 0.6019\n",
      "Epoch 13/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7622 - acc: 0.6487Epoch 00012: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.7619 - acc: 0.6483 - val_loss: 0.9621 - val_acc: 0.5417\n",
      "Epoch 14/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8038 - acc: 0.6246Epoch 00013: val_acc did not improve\n",
      "64/64 [==============================] - 198s - loss: 0.8046 - acc: 0.6266 - val_loss: 0.9317 - val_acc: 0.5833\n",
      "Epoch 15/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8037 - acc: 0.6501Epoch 00014: val_acc did not improve\n",
      "64/64 [==============================] - 197s - loss: 0.8027 - acc: 0.6517 - val_loss: 0.9302 - val_acc: 0.5856\n",
      "Epoch 16/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7894 - acc: 0.6435Epoch 00015: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.7893 - acc: 0.6412 - val_loss: 0.9534 - val_acc: 0.5185\n",
      "Epoch 17/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7654 - acc: 0.6591Epoch 00016: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.7639 - acc: 0.6596 - val_loss: 0.9099 - val_acc: 0.5995\n",
      "Epoch 18/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7931 - acc: 0.6375Epoch 00017: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.7940 - acc: 0.6363 - val_loss: 0.9213 - val_acc: 0.5880\n",
      "Epoch 19/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7507 - acc: 0.6804Epoch 00018: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.7522 - acc: 0.6786 - val_loss: 0.9570 - val_acc: 0.5394\n",
      "Epoch 20/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7273 - acc: 0.6598Epoch 00019: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.7274 - acc: 0.6583 - val_loss: 0.9281 - val_acc: 0.5741\n",
      "Epoch 21/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7849 - acc: 0.6395Epoch 00020: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.7832 - acc: 0.6412 - val_loss: 0.9291 - val_acc: 0.5741\n",
      "Epoch 22/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7331 - acc: 0.6717Epoch 00021: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.7341 - acc: 0.6729 - val_loss: 0.9435 - val_acc: 0.5671\n",
      "Epoch 23/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7744 - acc: 0.6469Epoch 00022: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.7773 - acc: 0.6456 - val_loss: 0.9250 - val_acc: 0.5810\n",
      "Epoch 24/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7422 - acc: 0.6771Epoch 00023: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.7417 - acc: 0.6783 - val_loss: 0.9345 - val_acc: 0.5972\n",
      "Epoch 25/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7105 - acc: 0.6962Epoch 00024: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.7128 - acc: 0.6951 - val_loss: 0.9380 - val_acc: 0.5764\n",
      "Epoch 26/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7437 - acc: 0.6667Epoch 00025: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.7447 - acc: 0.6671 - val_loss: 0.9455 - val_acc: 0.5625\n",
      "Epoch 27/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.6998 - acc: 0.6906Epoch 00026: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.6984 - acc: 0.6915 - val_loss: 0.9434 - val_acc: 0.5810\n",
      "Epoch 28/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7358 - acc: 0.6690Epoch 00027: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.7358 - acc: 0.6703 - val_loss: 0.9536 - val_acc: 0.5625\n",
      "Epoch 29/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7024 - acc: 0.6950Epoch 00028: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.7058 - acc: 0.6919 - val_loss: 0.9697 - val_acc: 0.5347\n",
      "Epoch 30/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7200 - acc: 0.6834Epoch 00029: val_acc did not improve\n",
      "64/64 [==============================] - 197s - loss: 0.7176 - acc: 0.6844 - val_loss: 0.9698 - val_acc: 0.5833\n",
      "Epoch 31/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7250 - acc: 0.6774Epoch 00030: val_acc did not improve\n",
      "64/64 [==============================] - 197s - loss: 0.7252 - acc: 0.6756 - val_loss: 0.9602 - val_acc: 0.5856\n",
      "Epoch 32/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7084 - acc: 0.6864Epoch 00031: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.7064 - acc: 0.6864 - val_loss: 0.9647 - val_acc: 0.5694\n",
      "Epoch 33/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7144 - acc: 0.6824Epoch 00032: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.7144 - acc: 0.6825 - val_loss: 0.9885 - val_acc: 0.5486\n",
      "Epoch 34/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7011 - acc: 0.6928Epoch 00033: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.7023 - acc: 0.6907 - val_loss: 0.9674 - val_acc: 0.5833\n",
      "Epoch 35/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7170 - acc: 0.6921Epoch 00034: val_acc did not improve\n",
      "64/64 [==============================] - 197s - loss: 0.7208 - acc: 0.6891 - val_loss: 0.9486 - val_acc: 0.5671\n",
      "Epoch 36/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7008 - acc: 0.6925Epoch 00035: val_acc did not improve\n",
      "64/64 [==============================] - 194s - loss: 0.7001 - acc: 0.6944 - val_loss: 0.9499 - val_acc: 0.5880\n",
      "Epoch 37/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7237 - acc: 0.6838Epoch 00036: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.7220 - acc: 0.6849 - val_loss: 0.9385 - val_acc: 0.5810\n",
      "Epoch 38/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.6870 - acc: 0.7149Epoch 00037: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.6868 - acc: 0.7135 - val_loss: 0.9373 - val_acc: 0.5694\n",
      "Epoch 39/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.6916 - acc: 0.6854Epoch 00038: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.6899 - acc: 0.6854 - val_loss: 0.9664 - val_acc: 0.5648\n",
      "Epoch 40/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.6908 - acc: 0.6998Epoch 00039: val_acc did not improve\n",
      "64/64 [==============================] - 197s - loss: 0.6920 - acc: 0.6996 - val_loss: 0.9669 - val_acc: 0.5694\n",
      "Epoch 41/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.6996 - acc: 0.6826Epoch 00040: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.7037 - acc: 0.6807 - val_loss: 0.9814 - val_acc: 0.5347\n",
      "Epoch 42/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.6916 - acc: 0.6997Epoch 00041: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.6920 - acc: 0.7005 - val_loss: 0.9396 - val_acc: 0.5694\n",
      "Epoch 43/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.6687 - acc: 0.7027Epoch 00042: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.6652 - acc: 0.7054 - val_loss: 0.9771 - val_acc: 0.5579\n",
      "Epoch 44/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.7080 - acc: 0.6903Epoch 00043: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.7060 - acc: 0.6913 - val_loss: 0.9929 - val_acc: 0.5694\n",
      "Epoch 45/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.6786 - acc: 0.6933Epoch 00044: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.6779 - acc: 0.6913 - val_loss: 0.9632 - val_acc: 0.5694\n",
      "Epoch 46/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.6733 - acc: 0.7116Epoch 00045: val_acc did not improve\n",
      "64/64 [==============================] - 197s - loss: 0.6723 - acc: 0.7132 - val_loss: 0.9779 - val_acc: 0.5486\n",
      "Epoch 47/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.6859 - acc: 0.6945Epoch 00046: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.6854 - acc: 0.6954 - val_loss: 0.9744 - val_acc: 0.5417\n",
      "Epoch 48/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.6382 - acc: 0.7233Epoch 00047: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.6416 - acc: 0.7218 - val_loss: 0.9633 - val_acc: 0.5579\n",
      "Epoch 49/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.6565 - acc: 0.7233Epoch 00048: val_acc did not improve\n",
      "64/64 [==============================] - 197s - loss: 0.6563 - acc: 0.7208 - val_loss: 0.9762 - val_acc: 0.5556\n",
      "Epoch 50/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.6891 - acc: 0.7040Epoch 00049: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.6903 - acc: 0.7018 - val_loss: 0.9813 - val_acc: 0.5810\n",
      "Finished tuning\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting to Tune Model\\n\")\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=nb_epoch,\n",
    "    validation_data=validation_generator,\n",
    "validation_steps=nb_validation_samples // batch_size,\n",
    "callbacks=callbacks_list)\n",
    "print('Finished tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_xception.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_xception.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOs:\n",
    "\n",
    "- more aggresive data augmentation\n",
    "- more aggressive dropout\n",
    "- use of L1 and L2 regularization (also known as \"weight decay\")\n",
    "- fine-tuning one more convolutional block (alongside greater regularization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open(\"model_xception.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(\"weights-improvement-11-0.60.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Read Data\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                                  target_size=(img_width, img_height),\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "# Calculate class posteriors probabilities\n",
    "y_probabilities = model.predict_generator(test_generator, 32)\n",
    "print(len(y_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class labels\n",
    "y_classes = to_categorical(y_probabilities)\n",
    "filenames = [filename.split('\\\\')[1] for filename in test_generator.filenames]\n",
    "ids = [filename.split('.')[0] for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = LESSON_HOME_DIR+'/results/'\n",
    "results_name = 'predictions.csv'\n",
    "# save results as a csv file in the specified results directory\n",
    "with open(os.path.join(results_path, results_name), 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(('image_name', 'Type_1', 'Type_2', 'Type_3'))\n",
    "    writer.writerows(zip(filenames, y_probabilities[:, 0], y_probabilities[:, 1], y_probabilities[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

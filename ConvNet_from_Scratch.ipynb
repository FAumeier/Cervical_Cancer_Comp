{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# small convnet from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 299, 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/valid'\n",
    "nb_train_samples = 1037\n",
    "nb_validation_samples = 444\n",
    "nb_classes = 3  # number of classes\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 297, 297, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 297, 297, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 146, 146, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 146, 146, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 71, 71, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 78400)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                5017664   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 5,046,499\n",
      "Trainable params: 5,046,499\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1037 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 444 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See: https://github.com/fchollet/keras/issues/5475\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting to Tune Model\n",
      "\n",
      "Epoch 1/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 1.0512 - acc: 0.4841Epoch 00000: val_acc improved from -inf to 0.53472, saving model to weights-improvement-00-0.53.hdf5\n",
      "64/64 [==============================] - 221s - loss: 1.0505 - acc: 0.4824 - val_loss: 1.0244 - val_acc: 0.5347\n",
      "Epoch 2/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9932 - acc: 0.5230Epoch 00001: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.9925 - acc: 0.5216 - val_loss: 0.9492 - val_acc: 0.5347\n",
      "Epoch 3/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9885 - acc: 0.5128Epoch 00002: val_acc improved from 0.53472 to 0.53935, saving model to weights-improvement-02-0.54.hdf5\n",
      "64/64 [==============================] - 195s - loss: 0.9868 - acc: 0.5136 - val_loss: 0.9391 - val_acc: 0.5394\n",
      "Epoch 4/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9421 - acc: 0.5199Epoch 00003: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.9435 - acc: 0.5206 - val_loss: 0.9236 - val_acc: 0.5347\n",
      "Epoch 5/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9524 - acc: 0.5121Epoch 00004: val_acc did not improve\n",
      "64/64 [==============================] - 194s - loss: 0.9558 - acc: 0.5099 - val_loss: 0.9626 - val_acc: 0.5370\n",
      "Epoch 6/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9261 - acc: 0.5527Epoch 00005: val_acc improved from 0.53935 to 0.55324, saving model to weights-improvement-05-0.55.hdf5\n",
      "64/64 [==============================] - 195s - loss: 0.9265 - acc: 0.5539 - val_loss: 0.9209 - val_acc: 0.5532\n",
      "Epoch 7/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9375 - acc: 0.5359Epoch 00006: val_acc improved from 0.55324 to 0.57176, saving model to weights-improvement-06-0.57.hdf5\n",
      "64/64 [==============================] - 194s - loss: 0.9413 - acc: 0.5324 - val_loss: 0.9261 - val_acc: 0.5718\n",
      "Epoch 8/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9308 - acc: 0.5455Epoch 00007: val_acc did not improve\n",
      "64/64 [==============================] - 194s - loss: 0.9304 - acc: 0.5467 - val_loss: 0.9267 - val_acc: 0.5602\n",
      "Epoch 9/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9358 - acc: 0.5487Epoch 00008: val_acc did not improve\n",
      "64/64 [==============================] - 194s - loss: 0.9355 - acc: 0.5508 - val_loss: 0.9029 - val_acc: 0.5625\n",
      "Epoch 10/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9302 - acc: 0.5552Epoch 00009: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.9267 - acc: 0.5572 - val_loss: 0.9134 - val_acc: 0.5648\n",
      "Epoch 11/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9234 - acc: 0.5621Epoch 00010: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.9236 - acc: 0.5592 - val_loss: 0.9018 - val_acc: 0.5671\n",
      "Epoch 12/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8982 - acc: 0.5691Epoch 00011: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.8952 - acc: 0.5719 - val_loss: 0.9226 - val_acc: 0.5486\n",
      "Epoch 13/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9156 - acc: 0.5502Epoch 00012: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.9164 - acc: 0.5485 - val_loss: 0.9172 - val_acc: 0.5718\n",
      "Epoch 14/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9164 - acc: 0.5403Epoch 00013: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.9150 - acc: 0.5387 - val_loss: 0.9152 - val_acc: 0.5486\n",
      "Epoch 15/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9179 - acc: 0.5634Epoch 00014: val_acc did not improve\n",
      "64/64 [==============================] - 193s - loss: 0.9160 - acc: 0.5644 - val_loss: 0.9382 - val_acc: 0.5602\n",
      "Epoch 16/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9051 - acc: 0.5596Epoch 00015: val_acc did not improve\n",
      "64/64 [==============================] - 194s - loss: 0.9076 - acc: 0.5567 - val_loss: 0.9174 - val_acc: 0.5694\n",
      "Epoch 17/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8724 - acc: 0.5723Epoch 00016: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.8769 - acc: 0.5731 - val_loss: 0.9181 - val_acc: 0.5671\n",
      "Epoch 18/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8982 - acc: 0.5584Epoch 00017: val_acc improved from 0.57176 to 0.57870, saving model to weights-improvement-17-0.58.hdf5\n",
      "64/64 [==============================] - 194s - loss: 0.9002 - acc: 0.5575 - val_loss: 0.9285 - val_acc: 0.5787\n",
      "Epoch 19/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8601 - acc: 0.5998Epoch 00018: val_acc did not improve\n",
      "64/64 [==============================] - 193s - loss: 0.8600 - acc: 0.6002 - val_loss: 0.9204 - val_acc: 0.5787\n",
      "Epoch 20/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9253 - acc: 0.5440Epoch 00019: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.9224 - acc: 0.5453 - val_loss: 0.9321 - val_acc: 0.5741\n",
      "Epoch 21/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8538 - acc: 0.5790Epoch 00020: val_acc did not improve\n",
      "64/64 [==============================] - 194s - loss: 0.8536 - acc: 0.5826 - val_loss: 0.9146 - val_acc: 0.5509\n",
      "Epoch 22/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8901 - acc: 0.5807Epoch 00021: val_acc did not improve\n",
      "64/64 [==============================] - 194s - loss: 0.8919 - acc: 0.5814 - val_loss: 0.9210 - val_acc: 0.5764\n",
      "Epoch 23/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.9229 - acc: 0.5449Epoch 00022: val_acc improved from 0.57870 to 0.58333, saving model to weights-improvement-22-0.58.hdf5\n",
      "64/64 [==============================] - 195s - loss: 0.9216 - acc: 0.5442 - val_loss: 0.9177 - val_acc: 0.5833\n",
      "Epoch 24/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8768 - acc: 0.5832Epoch 00023: val_acc did not improve\n",
      "64/64 [==============================] - 194s - loss: 0.8844 - acc: 0.5819 - val_loss: 0.9445 - val_acc: 0.5509\n",
      "Epoch 25/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8597 - acc: 0.5899Epoch 00024: val_acc did not improve\n",
      "64/64 [==============================] - 194s - loss: 0.8595 - acc: 0.5895 - val_loss: 0.9712 - val_acc: 0.5648\n",
      "Epoch 26/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8814 - acc: 0.5552Epoch 00025: val_acc did not improve\n",
      "64/64 [==============================] - 197s - loss: 0.8795 - acc: 0.5563 - val_loss: 0.9157 - val_acc: 0.5718\n",
      "Epoch 27/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8516 - acc: 0.5988Epoch 00026: val_acc did not improve\n",
      "64/64 [==============================] - 197s - loss: 0.8537 - acc: 0.5983 - val_loss: 0.9221 - val_acc: 0.5741\n",
      "Epoch 28/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8702 - acc: 0.5857Epoch 00027: val_acc did not improve\n",
      "64/64 [==============================] - 198s - loss: 0.8684 - acc: 0.5873 - val_loss: 0.9228 - val_acc: 0.5833\n",
      "Epoch 29/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8471 - acc: 0.5891Epoch 00028: val_acc did not improve\n",
      "64/64 [==============================] - 201s - loss: 0.8509 - acc: 0.5868 - val_loss: 0.9312 - val_acc: 0.5648\n",
      "Epoch 30/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8404 - acc: 0.6037Epoch 00029: val_acc did not improve\n",
      "64/64 [==============================] - 198s - loss: 0.8390 - acc: 0.6031 - val_loss: 0.9729 - val_acc: 0.5833\n",
      "Epoch 31/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8659 - acc: 0.5869Epoch 00030: val_acc did not improve\n",
      "64/64 [==============================] - 194s - loss: 0.8631 - acc: 0.5885 - val_loss: 0.9181 - val_acc: 0.5810\n",
      "Epoch 32/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8648 - acc: 0.5817Epoch 00031: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.8678 - acc: 0.5805 - val_loss: 0.9318 - val_acc: 0.5694\n",
      "Epoch 33/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8493 - acc: 0.5855Epoch 00032: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 196s - loss: 0.8468 - acc: 0.5890 - val_loss: 1.0199 - val_acc: 0.5810\n",
      "Epoch 34/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8573 - acc: 0.6060Epoch 00033: val_acc did not improve\n",
      "64/64 [==============================] - 194s - loss: 0.8560 - acc: 0.6073 - val_loss: 0.9238 - val_acc: 0.5741\n",
      "Epoch 35/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8622 - acc: 0.5887Epoch 00034: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.8628 - acc: 0.5902 - val_loss: 1.0707 - val_acc: 0.5694\n",
      "Epoch 36/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8686 - acc: 0.5994Epoch 00035: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.8654 - acc: 0.6017 - val_loss: 1.0204 - val_acc: 0.5648\n",
      "Epoch 37/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8480 - acc: 0.6147Epoch 00036: val_acc did not improve\n",
      "64/64 [==============================] - 197s - loss: 0.8484 - acc: 0.6139 - val_loss: 0.9516 - val_acc: 0.5648\n",
      "Epoch 38/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8907 - acc: 0.5921Epoch 00037: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.8882 - acc: 0.5916 - val_loss: 0.9540 - val_acc: 0.5671\n",
      "Epoch 39/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8450 - acc: 0.5958Epoch 00038: val_acc improved from 0.58333 to 0.59028, saving model to weights-improvement-38-0.59.hdf5\n",
      "64/64 [==============================] - 194s - loss: 0.8429 - acc: 0.5963 - val_loss: 0.9341 - val_acc: 0.5903\n",
      "Epoch 40/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8645 - acc: 0.6020Epoch 00039: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.8671 - acc: 0.6024 - val_loss: 0.9304 - val_acc: 0.5810\n",
      "Epoch 41/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8386 - acc: 0.6152Epoch 00040: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.8415 - acc: 0.6153 - val_loss: 0.9560 - val_acc: 0.5602\n",
      "Epoch 42/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8378 - acc: 0.6006Epoch 00041: val_acc did not improve\n",
      "64/64 [==============================] - 196s - loss: 0.8356 - acc: 0.6019 - val_loss: 0.9711 - val_acc: 0.5671\n",
      "Epoch 43/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8425 - acc: 0.6132Epoch 00042: val_acc did not improve\n",
      "64/64 [==============================] - 197s - loss: 0.8426 - acc: 0.6143 - val_loss: 0.9620 - val_acc: 0.5833\n",
      "Epoch 44/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8275 - acc: 0.6169Epoch 00043: val_acc improved from 0.59028 to 0.59491, saving model to weights-improvement-43-0.59.hdf5\n",
      "64/64 [==============================] - 195s - loss: 0.8232 - acc: 0.6180 - val_loss: 1.0666 - val_acc: 0.5949\n",
      "Epoch 45/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8577 - acc: 0.6045Epoch 00044: val_acc did not improve\n",
      "64/64 [==============================] - 194s - loss: 0.8563 - acc: 0.6058 - val_loss: 0.9560 - val_acc: 0.5764\n",
      "Epoch 46/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8345 - acc: 0.6020Epoch 00045: val_acc did not improve\n",
      "64/64 [==============================] - 193s - loss: 0.8361 - acc: 0.6004 - val_loss: 1.0907 - val_acc: 0.5556\n",
      "Epoch 47/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8279 - acc: 0.6313Epoch 00046: val_acc did not improve\n",
      "64/64 [==============================] - 193s - loss: 0.8283 - acc: 0.6292 - val_loss: 0.9619 - val_acc: 0.5810\n",
      "Epoch 48/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8200 - acc: 0.6368Epoch 00047: val_acc did not improve\n",
      "64/64 [==============================] - 195s - loss: 0.8168 - acc: 0.6395 - val_loss: 1.0094 - val_acc: 0.5741\n",
      "Epoch 49/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8448 - acc: 0.6288Epoch 00048: val_acc did not improve\n",
      "64/64 [==============================] - 194s - loss: 0.8452 - acc: 0.6278 - val_loss: 0.9329 - val_acc: 0.5856\n",
      "Epoch 50/50\n",
      "63/64 [============================>.] - ETA: 2s - loss: 0.8249 - acc: 0.6164Epoch 00049: val_acc did not improve\n",
      "64/64 [==============================] - 199s - loss: 0.8225 - acc: 0.6175 - val_loss: 1.0050 - val_acc: 0.5671\n",
      "Finished tuning\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting to Tune Model\\n\")\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "validation_steps=nb_validation_samples // batch_size,\n",
    "callbacks=callbacks_list)\n",
    "print('Finished tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('second_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

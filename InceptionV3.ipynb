{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create references to important directories we will use over and over\n",
    "import os, sys\n",
    "\n",
    "LESSON_HOME_DIR = '/home/paperspace/NBs/Cervical_Cancer_Comp'\n",
    "DATA_HOME_DIR = LESSON_HOME_DIR+'/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Instantiate plotting tool\n",
    "#In Jupyter notebooks, you will need to run this command before doing any plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Plan\n",
    "1. Create Validation and Sample sets\n",
    "2. Rearrange image files into their respective directories \n",
    "3. Finetune and Train model\n",
    "4. Generate predictions\n",
    "5. Validate predictions\n",
    "6. Submit predictions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/NBs/Cervical_Cancer_Comp/data\n",
      "mkdir: cannot create directory ‘valid’: File exists\n",
      "mkdir: cannot create directory ‘results’: File exists\n"
     ]
    }
   ],
   "source": [
    "#Create directories\n",
    "%cd $DATA_HOME_DIR\n",
    "%mkdir valid\n",
    "%mkdir results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/NBs/Cervical_Cancer_Comp/data/valid\n"
     ]
    }
   ],
   "source": [
    "#creating respecting class dirs in valid\n",
    "%cd valid/\n",
    "%ls\n",
    "%mkdir Type_1\n",
    "%mkdir Type_2\n",
    "%mkdir Type_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/paperspace/NBs/Cervical_Cancer_Comp/data/valid'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current dir\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/NBs/Cervical_Cancer_Comp/data/train\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mresults\u001b[0m/  \u001b[01;34mType_1\u001b[0m/  \u001b[01;34mType_2\u001b[0m/  \u001b[01;34mType_3\u001b[0m/  \u001b[01;34mvalid\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls\n",
    "g = glob('**/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "validation_dir = DATA_HOME_DIR+'valid/' \n",
    "\n",
    "for i in range(444): os.rename(shuf[i], validation_dir + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/NBs/Cervical_Cancer_Comp/data\n",
      "\u001b[0m\u001b[01;34mbak\u001b[0m/  \u001b[01;32mdownload.sh\u001b[0m*  \u001b[01;34mresults\u001b[0m/  \u001b[01;34mtest\u001b[0m/  \u001b[01;31mtest.7z\u001b[0m  \u001b[01;34mtrain\u001b[0m/  \u001b[01;31mtrain.7z\u001b[0m  \u001b[01;34mvalid\u001b[0m/\n",
      "/home/paperspace/NBs/Cervical_Cancer_Comp/data/valid/Type_1\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "# check valid dir for type 1\n",
    "%cd $DATA_HOME_DIR\n",
    "%ls\n",
    "%cd valid/Type_1\n",
    "%ls -1 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/NBs/Cervical_Cancer_Comp/data/valid\n",
      "/home/paperspace/NBs/Cervical_Cancer_Comp/data/valid/Type_2\n",
      "229\r\n"
     ]
    }
   ],
   "source": [
    "# check valid dir for type 2\n",
    "%cd ..\n",
    "%cd Type_2\n",
    "% ls -1 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/NBs/Cervical_Cancer_Comp/data/valid\n",
      "/home/paperspace/NBs/Cervical_Cancer_Comp/data/valid/Type_3\n",
      "139\r\n"
     ]
    }
   ],
   "source": [
    "# check valid dir for type 2\n",
    "%cd ..\n",
    "%cd Type_3\n",
    "% ls -1 | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = 'data/train'\n",
    "test_data_dir = 'data/test'\n",
    "# validation_data_dir = 'data/validation'\n",
    "\n",
    "\n",
    "nb_train_samples = 1037\n",
    "nb_validation_samples = 444"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we are using Inception or Xception, we need to set the inputShape  to 299×299 pixels, followed by updating preprocess  to use a separate pre-processing function that performs a different type of scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters for model\n",
    "nb_classes = 3  # number of classes\n",
    "img_width, img_height = 299, 299  # change based on the shape/structure of your images\n",
    "batch_size = 16  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU/GPU memory capacity (powers of 2 values).\n",
    "nb_epoch = 1  # number of iteration the algorithm gets trained. 1 As test run\n",
    "learn_rate = 0.045  # sgd learning rate\n",
    "momentum = 0.9  # sgd momentum to avoid local minimum\n",
    "transformation_ratio = .05  # how aggressive will be the data augmentation/transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Pre-trained InceptionV3 Model using imagenet dataset weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pre-Trained CNN Model using imagenet dataset for pre-trained weights\n",
    "base_model = InceptionV3(input_shape=(img_width, img_height, 3), weights='imagenet', include_top=False)\n",
    "print('Model Loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Defining own top model block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Top Model Block\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(nb_classes, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add your top layer block to your base model\n",
    "model = Model(base_model.input, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all layers of the based model that is already pre-trained.\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
